[
  {
    "id": 1,
    "question": "上学期学习的利用线性回归预测加州房价的例子，该线性回归模型可以看做是一个单层的神经网络。",
    "type": "true_false",
    "options": [
      "True",
      "False"
    ],
    "answer": "True"
  },
  {
    "id": 2,
    "question": "线性神经网络的训练过程中，如果我们将权重初始化为零，会发生什么。算法仍然有效吗？",
    "type": "multiple_choice",
    "options": [
      "A.权重初始化为零是理想选择，算法能快速收敛",
      "B.模型无法打破对称性，导致神经元行为一致，算法性能严重下降",
      "C.梯度爆炸问题会出现，但算法仍可正常训练",
      "D.权重初始化为零会导致所有输出为零，梯度无法更新，算法完全失效"
    ],
    "answer": "B"
  },
  {
    "id": 3,
    "question": "以下关于Softmax回归和Logistic回归区别的描述中，哪一项是正确的？",
    "type": "multiple_choice",
    "options": [
      "A.Softmax回归是Logistic回归的一种特例，专门用于处理多类别分类问题。",
      "B.Logistic回归使用Sigmoid函数作为激活函数，而Softmax回归使用ReLU函数作为激活函数。",
      "C.Logistic回归是二分类模型，其输出是一个标量概率值；Softmax回归是多分类模型，其输出是一个概率分布向量。",
      "D.两者均使用均方误差损失函数（Mean Squared Error）来训练模型。"
    ],
    "answer": "C"
  },
  {
    "id": 4,
    "question": "Pytorch中，训练模型的过程中用于计算梯度的函数是？",
    "type": "multiple_choice",
    "options": [
      "A.backward( )",
      "B.gred_( )",
      "C.update( )",
      "D.forward( )"
    ],
    "answer": "A"
  },
  {
    "id": 5,
    "question": "两个多层感知机模型：模型A（1个隐藏层，10个神经元）和模型B（3个隐藏层，每层20个神经元）。模型B的层数更深、神经元更多，因此其容量和表示能力一定强于模型A。",
    "type": "true_false",
    "options": [
      "True",
      "False"
    ],
    "answer": "False"
  },
  {
    "id": 6,
    "question": "在训练MLP时使用了Dropout技术。在训练时随机“丢弃”了一部分神经元。在模型预测阶段，为了模拟训练时大量神经元的随机组合效应，也应该继续随机丢弃一部分神经元。",
    "type": "true_false",
    "options": [
      "True",
      "False"
    ],
    "answer": "False"
  },
  {
    "id": 7,
    "question": "一个多层感知机，在训练集上准确率达到99%，但在测试集上只有70%。这可能是因为模型过拟合了，以下哪种方法不能有效防止过拟合？",
    "type": "multiple_choice",
    "options": [
      "A.增加训练数据量",
      "B.使用更复杂的模型（如增加隐藏层神经元数量）",
      "C.应用权重衰减（L2正则化）",
      "D.使用dropout技术"
    ],
    "answer": "A"
  },
  {
    "id": 8,
    "question": "使用Sigmoid函数作为一个10层MLP的激活函数，但发现训练初期梯度非常小，网络学习缓慢。这种现象最可能的原因是什么？",
    "type": "multiple_choice",
    "options": [
      "A.学习率设置过大",
      "B.发生了梯度爆炸",
      "C.模型陷入了局部最优",
      "D.发生了梯度消失"
    ],
    "answer": "D"
  },
  {
    "id": 9,
    "question": "关于“隐藏层”，以下哪个描述是最准确的",
    "type": "multiple_choice",
    "options": [
      "A.它的神经元数量是保密的，所以叫“隐藏”层",
      "B.它的输出值在训练数据中没有直接给出标签，是模型内部的特征表示",
      "C.它的权重在训练过程中是不可见的",
      "D.激活函数是ReLU"
    ],
    "answer": "B"
  },
  {
    "id": 10,
    "question": "在模型中使用了一个前向线性层，该层继承nn.Module，在init方法中通过nn.Parameter(torch.randn(3,3))初始化参数，并在forward方法中用该参数实现输入张量与权重的矩阵乘法运算。这个参数不会参与梯度计算",
    "type": "true_false",
    "options": [
      "True",
      "False"
    ],
    "answer": "False"
  },
  {
    "id": 11,
    "question": "在训练房价预测模型时，构建了 “线性层（8 维→ 4 维）→ReLU→线性层（ 4 维→ 1 维）” 的顺序组合网络。可以用nn.Sequential实现",
    "type": "true_false",
    "options": [
      "True",
      "False"
    ],
    "answer": "True"
  },
  {
    "id": 12,
    "question": "一个复杂模型在CPU上训练太慢，想转移到GPU上加速。为保证正常运行，需要确保以下哪项？",
    "type": "multiple_choice",
    "options": [
      "A.模型参数移动到GPU",
      "B.输入数据移动到GPU",
      "C.损失函数计算在GPU上进行",
      "D.以上所有"
    ],
    "answer": "D"
  },
  {
    "id": 13,
    "question": "在PyTorch中构建一个10层神经网络，要求第2层和第8层共享相同的参数（即在训练过程中始终保持一致）。以下哪种实现方式最正确、可靠、高效？",
    "type": "multiple_choice",
    "options": [
      "A.",
      "class Net(nn.Module):",
      "def __init__(self):",
      "super().__init__()",
      "self.layers = nn.ModuleList([nn.Linear(100, 100) for _ in range(10)])",
      "# 在初始化后手动复制参数",
      "self.layers[7].weight.data.copy_(self.layers[1].weight.data)",
      "self.layers[7].bias.data.copy_(self.layers[1].bias.data)"
    ],
    "answer": "A"
  },
  {
    "id": 14,
    "question": "B.",
    "type": "unknown",
    "options": [],
    "answer": ""
  },
  {
    "id": 15,
    "question": "C.",
    "type": "unknown",
    "options": [],
    "answer": ""
  },
  {
    "id": 16,
    "question": "D.",
    "type": "unknown",
    "options": [],
    "answer": ""
  },
  {
    "id": 17,
    "question": "在深度学习的早期研究以及现在的一些代码中，我们常常会看到使用标准差为0.01的高斯随机分布（即 weight = torch.randn(fan_in, fan_out) * 0.01）来初始化神经网络的权重。关于这种做法的原因和影响，以下哪个描述是最准确的？",
    "type": "multiple_choice",
    "options": [
      "A.选择0.01这个数值是为了确保所有参数在初始化时都是正值，从而加速模型收敛。",
      "B.这是一种简单的启发式方法，目的是让权重从一个接近零但又不完全为零的小范围开始，旨在避免梯度完全消失，同时防止激活值在初始阶段就出现饱和。",
      "C.标准差设为0.01是经过严格数学推导得出的最优值，适用于所有网络结构和激活函数。",
      "D.其主要目的是为了在训练开始时让损失函数达到一个较低的数值，从而减少模型达到收敛所需的总训练时间。"
    ],
    "answer": "B"
  },
  {
    "id": 18,
    "question": "小明正在设计一个识别猫狗图片的分类系统。他选择使用卷积神经网络（CNN）而不是传统的全连接神经网络，主要是希望CNN帮助解决以下哪个实际问题？",
    "type": "multiple_choice",
    "options": [
      "A.减少模型需要训练的权重数量，降低计算成本",
      "B.直接提取图片的颜色分布特征",
      "C.避免使用激活函数",
      "D.将图片压缩成更小的尺寸以便存储"
    ],
    "answer": "A"
  },
  {
    "id": 19,
    "question": "工程师小张正在设计一个卷积神经网络来识别监控视频中的行人。输入视频帧的分辨率为64×64像素，他使用一层卷积层，并希望输出特征图的尺寸保持为64×64不变。已知卷积核尺寸为3×3，步幅（stride）设为1。那么，为了实现输出尺寸不变，他应该将填充（padding）设置为多少？",
    "type": "multiple_choice",
    "options": [
      "A.0",
      "B.1",
      "C.2",
      "D.3"
    ],
    "answer": "C"
  },
  {
    "id": 20,
    "question": "一位工程师正在使用卷积神经网络处理一张分辨率为256x256的彩色卫星图像，以识别其中的建筑物。该图像是RGB格式。在网络的第一个卷积层中，他使用了32个尺寸为5x5的卷积核。请问这个卷积层的输出特征图有多少个通道？",
    "type": "multiple_choice",
    "options": [
      "A.3",
      "B.5",
      "C.32",
      "D.256"
    ],
    "answer": "C"
  },
  {
    "id": 21,
    "question": "在一个用于医学影像分析的深度CNN模型中，输入为1280×1280的X光片。网络包含多个卷积层，其中第一层和最后一层都使用了3×3的卷积核。由于网络深度的不同，这两个卷积层的输入特征图分别映射到原始图像的不同范围。关于这两个卷积核实际感受野的说法，正确的是？",
    "type": "multiple_choice",
    "options": [
      "A.两个卷积核的感受野相同，都是3×3像素",
      "B.第一个卷积核的感受野更大，因为它直接处理原始图像",
      "C.最后一个卷积核的感受野更大，因为它叠加了前面所有层的映射",
      "D.感受野大小只与卷积核尺寸有关，与网络深度无关"
    ],
    "answer": "C"
  },
  {
    "id": 22,
    "question": "小王正在设计一个CNN模型来识别MNIST数据集中的手写数字。他在几个卷积层后加入了最大池化层。以下关于池化层在该场景中主要作用的描述中，最准确的是？",
    "type": "multiple_choice",
    "options": [
      "A.显著增加模型的参数数量，使模型能学习更复杂的笔迹特征",
      "B.通过非线性变换让模型能拟合各种奇特的数字写法",
      "C.对特征图进行下采样，在减少计算量的同时，确保数字即使有轻微位置变化也能被正确识别",
      "D.增加特征图的通道数，从而同时检测数字的多个局部特征如拐角、弧线等"
    ],
    "answer": "C"
  },
  {
    "id": 23,
    "question": "在AlexNet模型中，部分MaxPooling层的结构为核尺寸3x3，步长（stride）为2。当一个尺寸为5x5的特征图输入到此池化层时，输出特征图的尺寸是多少？",
    "type": "multiple_choice",
    "options": [
      "A.3x3",
      "B.2x2",
      "C.1x1",
      "D.4x4"
    ],
    "answer": "B"
  },
  {
    "id": 24,
    "question": "VGG网络的核心组件是“VGG块”。下列哪个选项最准确地描述了一个典型的VGG块的结构特点？",
    "type": "multiple_choice",
    "options": [
      "A.一个卷积层后接一个池化层，通过这种交替结构逐步提取特征",
      "B.连续多个3x3卷积层后接一个2x2最大池化层，通过增加深度来提升性能。",
      "C.使用1x1卷积层进行降维，后接多个5x5卷积层以扩大感受野。",
      "D.每个块内使用多种不同尺寸的卷积核并行处理，最后将结果融合。"
    ],
    "answer": "B"
  },
  {
    "id": 25,
    "question": "GoogLeNet（Inception v1）在深度学习领域引人注目，其主要创新在于引入了一种全新的基础构建模块。这个模块的特点是什么？",
    "type": "multiple_choice",
    "options": [
      "A.连续堆叠多个小尺寸卷积核（如3x3）来构建深度网络。",
      "B.通过残差连接结构，将前一层的输出直接跳层传递到后面，以解决梯度消失问题。",
      "C.使用并行结构的多种尺寸卷积核和池化层，并将它们的输出在通道维度上进行拼接。",
      "D.整个网络由一个非常深的卷积序列构成，不使用任何全连接层。"
    ],
    "answer": "C"
  },
  {
    "id": 26,
    "question": "批量归一化是深度学习中的一种重要技术，它在训练过程中对数据进行转换。关于其工作原理和主要作用，下列哪个描述是最准确的？",
    "type": "multiple_choice",
    "options": [
      "A.它对整个训练数据集进行归一化，以加速模型收敛。",
      "B.它在每个训练批次中，对网络层输入数据的每个特征通道进行归一化，并通过可学习的参数进行缩放和偏移，以此缓解内部协变量偏移问题。",
      "C.它对网络的权重参数进行归一化处理，防止权重值变得过大，以此作为主要的正则化手段来防止过拟合。",
      "D.它只在测试阶段使用，对网络的输入图片进行标准化，使其符合预训练模型的输入要求。"
    ],
    "answer": "B"
  },
  {
    "id": 27,
    "question": "ResNet（残差网络）是深度学习发展中的一个里程碑式模型，它通过引入一种特殊的结构，成功解决了极深网络难以训练的问题。这种核心结构及其主要作用是什么？",
    "type": "multiple_choice",
    "options": [
      "A.使用并行排列的不同尺寸卷积核来提取多尺度特征，并通过1x1卷积控制计算量。",
      "B.通过跳跃连接将输入直接传递到后面的层，与经过卷积层的输出相加，使网络能够学习残差映射，缓解梯度消失问题。",
      "C.在每个卷积层后使用批量归一化和ReLU激活函数，并构建了统一的VGG块结构来增加网络深度。",
      "D.完全弃用全连接层，使用全局平均池化层将特征图直接转换为分类向量，大幅减少模型参数。"
    ],
    "answer": "B"
  },
  {
    "id": 28,
    "question": "常用的图像数据增广操作有哪些？",
    "type": "multiple_response",
    "options": [
      "A.图像翻转",
      "B.图像饱和度调整",
      "C.图像随机截取",
      "D.图像亮度调节"
    ],
    "answer": "ABCD"
  },
  {
    "id": 29,
    "question": "你准备使用微调（fine-tuning）方法，将一个在大型图像数据集（如ImageNet）上预训练好的卷积神经网络，应用到你自己拍摄的少量花卉分类图片上。以下哪种做法最符合微调的核心要求？",
    "type": "multiple_choice",
    "options": [
      "A.重新随机初始化网络所有权重，然后用花卉图片从头开始训练",
      "B.保持预训练模型的所有参数不变，仅调整最后分类层的输出节点数以匹配花卉类别数",
      "C.载入预训练模型权重，用较小的学习率在花卉图片上对整个网络进行少量迭代的训练",
      "D.直接使用预训练模型对花卉图片进行预测，不进行任何训练"
    ],
    "answer": "C"
  },
  {
    "id": 30,
    "question": "在微调一个预训练的图像分类模型（如ResNet）用于医学影像分类时，考虑到预训练模型底层学习的是通用特征（如边缘、纹理），而高层学习的是与原始数据集（如ImageNet）更相关的抽象特征，以下哪种微调策略通常最合理？",
    "type": "multiple_choice",
    "options": [
      "A.固定所有层的参数，只重新训练最后的分类层",
      "B.固定高层参数，只更新底层参数",
      "C.固定底层参数，只更新高层和分类层参数",
      "D.不对任何层进行固定，全部参数都参与更新"
    ],
    "answer": "C"
  },
  {
    "id": 31,
    "question": "在RCNN系列目标检测算法中，关于边界框的预测，以下描述最准确的是：",
    "type": "multiple_choice",
    "options": [
      "A.模型直接预测目标物体在图像中的精确边界框坐标。",
      "B.模型首先生成一系列预定义的锚框，然后预测每个锚框的类别。",
      "C.模型首先生成锚框，然后直接预测一个与锚框形状相同的新边界框。",
      "D.模型首先生成锚框，然后预测从锚框到真实边界框的偏移量。"
    ],
    "answer": "D"
  },
  {
    "id": 32,
    "question": "在一个目标检测项目的开发中，你需要根据模型的预测框与真实框的匹配程度来评估检测质量。团队决定，只有当预测框的位置足够准确时，才认为这是一个正确的检测。下列哪种指标最适合用来定量地衡量“位置足够准确”？",
    "type": "multiple_choice",
    "options": [
      "A.分类置信度：即模型预测框内包含目标物体的概率大小。",
      "B.交并比：即预测框与真实框的交集面积与并集面积的比值。",
      "C.像素精度：即预测框内被正确分类的像素点所占的比例。",
      "D.检测速度：即模型处理单张图像并输出所有预测框所需的时间。"
    ],
    "answer": "B"
  },
  {
    "id": 33,
    "question": "你训练了一个目标检测模型来识别图像中的水果。在对一张测试图片进行预测时，模型在同一个苹果周围输出了三个高度重叠的边界框（如下所示），每个框都带有“苹果”标签和不同的置信度（0.9, 0.85, 0.7）。作为后处理步骤，你应该采用下列哪种方法来确保每个苹果只对应一个最准确的边界框？",
    "type": "multiple_choice",
    "options": [
      "A.置信度阈值过滤：设置一个阈值（如0.8），只保留置信度高于此阈值的预测框。",
      "B.非最大抑制：首先选择置信度最高的框，然后抑制掉与其高度重叠且属于同一类别的其他预测框。",
      "C.边界框聚类：将所有预测框的坐标进行平均，生成一个全新的边界框。",
      "D.多尺度融合：将不同尺寸特征图上得到的预测框合并在一起，以捕获更多细节。"
    ],
    "answer": "B"
  },
  {
    "id": 34,
    "question": "你的团队正在开发一个车辆检测系统，需要对图像中上千个候选区域进行识别和定位。初期使用R-CNN模型，发现检测速度极慢，主要瓶颈在于每个候选区域都需要独立通过CNN进行特征提取，计算冗余巨大。为了显著提升系统效率，下列哪种改进策略最符合Fast R-CNN的核心思想？",
    "type": "multiple_choice",
    "options": [
      "A.放弃使用CNN，转而使用更轻量级的传统特征提取方法，如HOG特征。",
      "B.在整个图像上仅执行一次CNN前向传播，得到全局特征图，然后通过“感兴趣区域池化”从该特征图上为每个候选区域提取固定大小的特征。",
      "C.大幅减少生成的候选区域数量，即使这可能牺牲一些对小物体的检测能力。",
      "D.将特征提取和分类任务部署到两个不同的专用硬件上，通过并行计算来减少时间。"
    ],
    "answer": "B"
  },
  {
    "id": 35,
    "question": "你正在为一个自动驾驶的自行车机器人选择目标检测模型。该机器人搭载的处理器计算能力有限，但对实时性要求极高（需要极高的帧率）。在模型评估阶段，你发现Fast R-CNN准确度不错，但速度较慢；而YOLOv1速度极快，但偶尔会将多个小物体检测成一个。从这两种算法的根本性差异来看，造成上述现象的核心原因最可能是：",
    "type": "multiple_choice",
    "options": [
      "A.Fast R-CNN在CPU上运行，而YOLOv1在GPU上运行。",
      "B.Fast R-CNN使用了更深的神经网络 backbone，导致其特征提取能力更强。",
      "C.Fast R-CNN是一个“两阶段”检测器，先生成候选区域再分类；而YOLOv1是一个“单阶段”检测器，将检测视为一个直接的回归问题。",
      "D.YOLOv1在训练时使用的数据集包含的物体类别比Fast R-CNN更少。"
    ],
    "answer": "C"
  },
  {
    "id": 36,
    "question": "在一阶马尔科夫模型中，该假设如何简化序列中状态（如句子中的单词）的依赖关系？",
    "type": "multiple_choice",
    "options": [
      "A.当前状态与所有过去和未来的状态都无关。",
      "B.当前状态的概率仅由其前一个状态决定。",
      "C.当前状态的概率由其前两个状态共同决定。",
      "D.当前状态的概率需要由整个历史序列决定。"
    ],
    "answer": "B"
  },
  {
    "id": 37,
    "question": "关于自回归模型（Autoregressive Model）的核心思想，以下哪一项描述是最准确的？",
    "type": "multiple_choice",
    "options": [
      "A.模型利用外部标签信息来预测序列中的每一个元素。",
      "B.模型使用序列中未来的已知元素来预测过去缺失的元素。",
      "C.模型在预测序列的下一个元素时，依赖于其自身过去已生成的元素。",
      "D.模型同时并行地生成整个序列的所有元素，不依赖历史信息。"
    ],
    "answer": "C"
  },
  {
    "id": 38,
    "question": "在隐马尔可夫模型中，其名称中的“隐”字，指的是什么？",
    "type": "multiple_choice",
    "options": [
      "A.模型的参数是隐藏起来、无法直接学习的。",
      "B.模型的状态转移过程是隐藏的、不可观测的。",
      "C.模型内部的数学计算过程对使用者是隐藏的。",
      "D.模型输出的观测序列是隐藏的、不存在的。"
    ],
    "answer": "B"
  },
  {
    "id": 39,
    "question": "在训练一个现代语言模型之前，为什么通常需要对原始文本语料库进行“分词”操作？",
    "type": "multiple_choice",
    "options": [
      "A.为了将文本翻译成英文，以便模型统一处理。",
      "B.为了将连续的字符序列切分成具有语义的离散基本单元，作为模型的输入。",
      "C.为了删除文本中的所有停用词（如“的”、“了”），只保留关键词。",
      "D.为了自动修正文本中的拼写和语法错误，净化语料。"
    ],
    "answer": "B"
  },
  {
    "id": 40,
    "question": "在循环神经网络中，“隐变量”（或“隐藏状态”）的主要作用是什么？",
    "type": "multiple_choice",
    "options": [
      "A.存储模型最终需要输出的预测结果。",
      "B.存储和传递序列在历史时间步的摘要信息。",
      "C.决定模型参数中哪些部分需要被随机丢弃以防止过拟合。",
      "D.作为一个临时变量，仅在当前时间步的计算中使用，然后被丢弃。"
    ],
    "answer": "B"
  },
  {
    "id": 41,
    "question": "在英译中机器翻译任务中，处理句子 “The cat chased the mouse” 时，自注意力机制与循环神经网络（RNN）的处理方式差异主要体现在？。",
    "type": "multiple_choice",
    "options": [
      "A.自注意力机制只能处理 5 个单词以内的短句，RNN 可处理更长句子",
      "B.自注意力机制能同时 “看到”“cat”“chased”“mouse” 等所有单词的关联，RNN 需从 “The” 开始逐个顺序读取",
      "C.自注意力机制必须先将单词转为独热编码才能计算，RNN 可直接用 Word Embedding",
      "D.自注意力机制无法区分 “cat” 和 “mouse” 的语义，RNN 能通过顺序记忆实现区分"
    ],
    "answer": "B"
  },
  {
    "id": 42,
    "question": "某 NLP 模型分析句子 “小红带了一本书，她在地铁上读完了它” 时，需计算代词 “她” 与句中其他成分的关联性。此时用于表示 “她” 与 “小红” 关联性强弱的符号是？（ ）",
    "type": "multiple_choice",
    "options": [
      "A.α（阿尔法）",
      "B.q（Query，查询向量）",
      "C.k（Key，键向量）",
      "D.v（Value，值向量）"
    ],
    "answer": "D"
  },
  {
    "id": 43,
    "question": "在 “中文句子‘人工智能很重要’→英文翻译‘Artificial intelligence is important’” 的任务中，Transformer 解码器生成 “intelligence” 一词时，调用的交叉注意力模块中，Query（q）、Key（k）、Value（v）的来源是？（ ）",
    "type": "multiple_choice",
    "options": [
      "A.q、k、v 均来自 “人工智能很重要” 的编码器输出",
      "B.q 来自解码器已生成的 “Artificial” 向量，k、v 来自编码器输出",
      "C.q、k、v 均来自解码器已生成的 “Artificial” 向量",
      "D.q 来自编码器输出，k、v 来自解码器已生成的 “Artificial” 向量"
    ],
    "answer": "A"
  },
  {
    "id": 44,
    "question": "某图像处理模型需识别图片中 “小孩抱着玩具熊” 的细节，对比 CNN 与自注意力机制的处理逻辑，下列描述符合实际场景的是？（ ）",
    "type": "multiple_choice",
    "options": [
      "A.CNN 能直接关注 “小孩的手” 与 “玩具熊” 的全局关联，自注意力机制只能看局部像素",
      "B.自注意力机制可直接捕捉 “小孩” 与 “玩具熊” 的整体位置关系，CNN 需通过多层卷积堆叠才能扩大感受野",
      "C.CNN 的卷积核参数是动态学习的，自注意力机制的注意力矩阵是固定不变的",
      "D.两者无法通过调整参数适配该图像识别场景"
    ],
    "answer": "B"
  },
  {
    "id": 45,
    "question": "某语音助手需处理用户一段 15 秒的语音指令（语音信号每秒约 100 帧，共 1500 帧），为避免注意力计算量过大，模型最可能采用的优化方式是？（ ）",
    "type": "multiple_choice",
    "options": [
      "A.直接生成 1500×1500 的完整注意力矩阵，保证计算精度",
      "B.使用 “截断注意力（Truncated Self-attention）”，仅让注意力关注相邻的 200 帧区域",
      "C.取消位置编码，减少 1500 帧的序列信息冗余",
      "D.用传统 RNN 替代自注意力机制，完全规避矩阵计算"
    ],
    "answer": "B"
  },
  {
    "id": 46,
    "question": "关于Diffusion模型的基本过程，下列哪一项描述是正确的？",
    "type": "multiple_choice",
    "options": [
      "A.前向加噪过程（扩散过程）中，模型逐步学习从噪声中恢复原始图像",
      "B.模型训练阶段的目标是学习如何向图像中添加高斯噪声",
      "C.前向加噪过程通过逐步添加噪声将图像破坏为纯噪声，模型训练则学习从噪声中重建图像",
      "D.模型训练完成后，直接通过一次前向传播即可从噪声生成清晰图像"
    ],
    "answer": "C"
  },
  {
    "id": 47,
    "question": "在条件Diffusion模型（Text-to-Image）的训练过程中，关于文本条件输入的使用方式，下列哪一项是正确的？",
    "type": "multiple_choice",
    "options": [
      "A.模型在每一步去噪训练时，会接收不同的文本描述作为条件输入",
      "B.模型仅在训练开始时接收一次文本条件，后续去噪步骤不再使用",
      "C.模型在每一步去噪训练时，都会接收同一个文本描述作为条件输入",
      "D.文本条件仅在推理阶段使用，训练时模型完全不需要文本输入"
    ],
    "answer": "C"
  },
  {
    "id": 48,
    "question": "关于Diffusion模型中FID（Fréchet Inception Distance）指标的说法，下列哪一项是正确的？",
    "type": "multiple_choice",
    "options": [
      "A.FID计算的是单张生成图像与单张真实图像之间的像素级差异",
      "B.FID值越大，表明生成图像的质量和多样性越好",
      "C.FID通过比较生成图像集和真实图像集在特征空间中的分布距离来评估模型性能",
      "D.FID主要衡量的是模型生成图像的速度，数值越小代表生成效率越高"
    ],
    "answer": "C"
  },
  {
    "id": 49,
    "question": "关于Stable Diffusion模型，下列哪一项描述是正确的？",
    "type": "multiple_choice",
    "options": [
      "A.Stable Diffusion直接在原始像素空间进行所有扩散和去噪操作",
      "B.Stable Diffusion通过编码器将图像压缩到潜空间，并在潜空间完成扩散过程的核心操作",
      "C.Stable Diffusion的“压缩”步骤只是为了减少存储占用，对生成质量没有实质性影响",
      "D.Stable Diffusion在潜空间进行扩散，但“理解”图像的步骤只在解码器输出时才发生"
    ],
    "answer": "B"
  },
  {
    "id": 50,
    "question": "在训练Stable Diffusion（文本到图像生成）模型时，关于噪声添加的位置，下列哪一项是正确的？",
    "type": "multiple_choice",
    "options": [
      "A.随机噪声直接添加到原始RGB图像的像素上",
      "B.随机噪声添加到从图像通过编码器得到的潜空间表示上",
      "C.随机噪声同时添加到原始图像和文本嵌入向量上",
      "D.随机噪声只添加到UNet模型的中间层特征上"
    ],
    "answer": "B"
  }
]